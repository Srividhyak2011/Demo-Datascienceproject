{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srividhyak2011/Demo-Datascienceproject/blob/main/M5_MP1_NB_CT_Medical_Image_Classification_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "powered-thong"
      },
      "source": [
        "# Applied Data Science and Machine Intelligence\n",
        "## A program by IIT Madras and TalentSprint\n",
        "### Mini Project: Cancer Detection in CT Scan Images using CNN\n",
        "\n"
      ],
      "id": "powered-thong"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "operating-latter"
      },
      "source": [
        "## Un-Graded"
      ],
      "id": "operating-latter"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "## Learning Objectives"
      ],
      "id": "maritime-miami"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* load and visualise the images\n",
        "\n",
        "* Extract features of images and reshape them\n",
        "\n",
        "* implement CNN using keras"
      ],
      "id": "nljJR6CwfZN_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29152de7"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Effectively classifying medical images play an essential role in aiding clinical care and treatment. For example, Analysis X-ray is the best approach to diagnose pneumonia which causes about 50,000 people to die per year in the US , but classifying pneumonia from chest X-rays needs professional radiologists which is a rare and expensive resource for some regions.\n",
        "\n",
        "The use of the traditional machine learning methods, such as support vector methods (SVMs), in medical image classification, began long ago. However, these methods have the following disadvantages: the performance is far from the practical standard, and the developing of them is quite slow in recent years. Also, the feature extracting and selection are time-consuming and vary according to different objects . The deep neural networks (DNN), especially the convolutional neural networks (CNNs), are widely used in changing image classification tasks and have achieved significant performance since 2012 . Some research on medical image classification by CNN has achieved performances rivaling human experts. For example, CheXNet, a CNN with 121 layers trained on a dataset with more than 100,000 frontal-view chest X-rays (ChestX-ray 14), achieved a better performance than the average performance of four radiologists.\n",
        "\n",
        "The medical images are hard to collect, as the collecting and labeling of medical data confronted with both data privacy concerns and the requirement for time-consuming expert explanations. In the two general resolving directions, one is to collect more data, such as crowdsourcing  or digging into the existing clinical reports .\n",
        "\n",
        "With the different CNN-based deep neural networks developed and achieved a significant result on ImageNet Challenger, which is the most significant image classification and segmentation challenge in the image analyzing field . The CNN-based deep neural system is widely used in the medical classification task. CNN is an excellent feature extractor, therefore utilizing it to classify medical images can avoid complicated and expensive feature engineering, presented a customized CNN with shallow ConvLayer to classify image patches of lung disease.\n"
      ],
      "id": "29152de7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "#### CT images from cancer imaging archive with contrast and patient age\n",
        "The dataset is designed to allow for different methods to be tested for examining the trends in CT image data associated with using contrast and patient age. The basic idea is to identify image textures, statistical patterns and features correlating strongly with these traits and possibly build simple tools for automatically classifying these images when they have been misclassified (or finding outliers which could be suspicious cases, bad measurements, or poorly calibrated machines)\n",
        "Data\n",
        "\n",
        "The data are a tiny subset of images from the cancer imaging archive. They consist of the middle slice of all CT images taken where valid age, modality, and contrast tags could be found. This results in 475 series from 69 different patients.\n",
        "\n",
        "TCIA Archive Link - https://wiki.cancerimagingarchive.net/display/Public/TCGA-LUAD"
      ],
      "id": "surprising-uruguay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ],
      "id": "ih-oasWmdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "To build and improve upon a CNN model for the classification of medical images and achieve a high accuracy final model."
      ],
      "id": "qfWGmjNHdZul"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "GjjK1Sa-ddYS"
      },
      "source": [
        "#@title Download the data\n",
        "!gdown \"1-C-0X_a2uqVjoUfiZ2RYLIxO4qAxPqdM\"\n",
        "!unzip --qq \"CT Medical images.zip\"\n",
        "!rm -rf \"full_archive.npz\"\n",
        "!rm -rf \"overview.csv\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "GjjK1Sa-ddYS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ],
      "id": "abstract-stocks"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom"
      ],
      "metadata": {
        "id": "8O1sSLRUdZQQ"
      },
      "id": "8O1sSLRUdZQQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advisory-knowing"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pydicom as dicom\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Keras libraries\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras import regularizers, optimizers, metrics\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout,BatchNormalization\n",
        "from keras.layers import Conv2D,MaxPooling2D\n"
      ],
      "id": "advisory-knowing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4bF_GJdZuo"
      },
      "source": [
        "###**Excercise 1**\n",
        "\n",
        "### Loading Images\n",
        "\n",
        "#### Loading images using pydicom library\n",
        "\n",
        "* Use pydicom library to load images\n",
        "* Print the image dimensions(in pixels)\n",
        "\n",
        "   Hint:  [Pydicom library documentation](https://pydicom.github.io/)"
      ],
      "id": "gp4bF_GJdZuo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc5c2362"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "fc5c2362",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUY3yNrdaABY"
      },
      "source": [
        "###**Excercise 2**\n",
        "### Visualisation of images"
      ],
      "id": "NUY3yNrdaABY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ca63666"
      },
      "source": [
        "#### Visualise any one image each for file name ending with contrast 0 and  1\n",
        "\n"
      ],
      "id": "9ca63666"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c414e14e"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "c414e14e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MRpw70ikBwA"
      },
      "source": [
        "###**Excercise 3**\n",
        "### Feature Extraction - Extract the following features\n",
        "\n",
        "####1. Pixel spacing\n",
        "####2. Slice thickness\n",
        "####3. aspect_ratio1 = $\\frac{Pixel\\_spacing[1]}{Pixel\\_spacing[0]}$\n",
        "\n",
        "####4. aspect_ratio2 = $\\frac{Pixel\\_spacing[1]}{Slice\\_thickness}$\n",
        "\n",
        "####5. aspect_ratio3 = $\\frac{Slice\\_thickness}{Pixel\\_spacing[0]}$\n",
        "\n",
        "Refer above defintions [here](https://dicom.innolitics.com/ciods/rt-dose/image-plane)\n"
      ],
      "id": "_MRpw70ikBwA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbfQyg61jEbv"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "qbfQyg61jEbv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bet0gRi742o9"
      },
      "source": [
        "###**Excercise 4**\n",
        "### Prepare a 3D volume data\n",
        "\n",
        "* Prepare a 3D volume data from images\n",
        "\n",
        "* Reshape the 3D volume data as a stack of images"
      ],
      "id": "bet0gRi742o9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRmTGlTP42pD"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "JRmTGlTP42pD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-FSvc27_64O"
      },
      "source": [
        "###**Excercise 5**\n",
        "### CNN for image classification\n",
        "\n",
        "* #### Building CNN\n",
        "\n",
        "* #### Use Image Data Generator as image input while fitting the model\n",
        "\n",
        "* #### Train it (Use 20 epochs for limited compute power)"
      ],
      "id": "G-FSvc27_64O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Guawf8U_64S"
      },
      "source": [
        "\n",
        "\n",
        "* Define the keras model and initialize the layers\n",
        "  - Ensure the input layer is specified with correct image size as input. This can be specified when creating the first layer with the input_shape argument.\n",
        "* Speicify number of filters Kernel size, Pool size and activation function\n",
        "  - filters,kernel_size and activation arguments of Conv2D layer can be used\n",
        "  - pool_size argument of MaxPool2D can be used to set Pool size\n",
        "* Compile the model\n",
        "  - Specify the loss function (to evaluate a set of weights), the optimizer (is used to search through different weights for the network) and any optional metrics to collect and report during training.\n",
        "* Fit and Evaluate the model\n",
        "  - Fit the data by specifying epochs and evaluate the model"
      ],
      "id": "0Guawf8U_64S"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eMm6CWljLnm"
      },
      "source": [
        "# Step 1 - Build the architecture\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "-eMm6CWljLnm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2R8QP0EjLnn"
      },
      "source": [
        "# Step 2 - Compile the model\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "r2R8QP0EjLnn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugvAPL9YjLno"
      },
      "source": [
        "# Step 3 - Train the model\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ugvAPL9YjLno"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFXGt8h57By"
      },
      "source": [
        "###**Excercise 6**\n",
        "### Prediction and Evaluation Metrics\n",
        "\n",
        "* Evaluate the trained model on test set\n"
      ],
      "id": "RTFXGt8h57By"
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "UIYtgOaY6n6s"
      },
      "id": "UIYtgOaY6n6s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w34gbejXvLUs"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "w34gbejXvLUs",
      "execution_count": null,
      "outputs": []
    }
  ]
}