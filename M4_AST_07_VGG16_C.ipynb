{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srividhyak2011/Demo-Datascienceproject/blob/main/M4_AST_07_VGG16_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "powered-thong"
      },
      "source": [
        "# Applied Data Science and Machine Intelligence\n",
        "## A program by IITM and TalentSprint\n",
        "### Assignment 07: VGG16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWNasi5jFnef"
      },
      "source": [
        "## VGG16\n",
        "\n",
        "The VGG16- convolutional network, is trained on ImageNet dataset (1000 classes) which is capable of extracting features from an image and train its fully connected network in order to classify different types of retinal damage instead of objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OiFi8nj77AW"
      },
      "source": [
        "## Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWMVQWk58aXm"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqosl928dBA"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8ptIQOnnbwbz"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M4_AST_07_VGG16_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    #ipython.magic(\"sx wget -q https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/breast_cancer.csv\")\n",
        "    #ipython.magic(\"sx wget -q https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/iris.csv\")\n",
        "    #ipython.magic(\"sx wget -q https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/Hitters.csv\")\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://adsmi-iitm.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download Dataset\n",
        "!gdown https://drive.google.com/uc?id=1BzHhdI4Fq4IrZ2KOfvA1Fy3sYnF0s0I6\n",
        "!gdown https://drive.google.com/uc?id=1FSs7BCjbkQoU-AEu2zqF4H-SAYQ8Y0qS\n",
        "\n",
        "!unzip test1.zip\n",
        "!unzip train.zip"
      ],
      "metadata": {
        "id": "WVxJjsA0Ywqr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "P3q1kRYO-dZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqdxOYpq9exp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalMaxPooling2D, Dropout, BatchNormalization, Input\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import load_img\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras import applications\n",
        "from keras import layers\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../content\" ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Traning Data"
      ],
      "metadata": {
        "id": "iWP31pYy-fSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of filenames from the specified directory\n",
        "filenames = os.listdir(\"/content/train\")\n",
        "# Initialize an empty list to store the categories\n",
        "categories = []\n",
        "# Process each filename to extract the category information\n",
        "for filename in filenames:\n",
        "  # Split the filename by '.' to remove the file extension\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Rc9ULNsm9iFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See Total In count"
      ],
      "metadata": {
        "id": "TwLWnZiQ-iTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['category'].value_counts().plot.bar()"
      ],
      "metadata": {
        "id": "k2OvpC0Y9nC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See sample image"
      ],
      "metadata": {
        "id": "VBumHcPJ-ktB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = random.choice(filenames)\n",
        "image = load_img(\"../content/train/\"+sample)\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "PaBkxX7q9pVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RnRtZ4tbSoH"
      },
      "source": [
        "### Loading VGG16 model with pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_size = 224\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in pre_trained_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in pre_trained_model.layers[15:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)"
      ],
      "metadata": {
        "id": "dMVstBl09uRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model to train it and we are using binary_crossentropy and optimizer SGD and for metrics accuracy.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "7-cg-9RIPUQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have defined our model above. Let us check out the summary of this model and then compile it and train."
      ],
      "metadata": {
        "id": "O1OsBdnuvpxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wEE4VbupPVvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the Data"
      ],
      "metadata": {
        "id": "FYZIIjDX-pn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.1)\n",
        "\n",
        "train_df = train_df.reset_index()\n",
        "validate_df = validate_df.reset_index()\n",
        "\n",
        "# Reduce the number of samples for fast testing code purpose\n",
        "# validate_df = validate_df.sample(n=100).reset_index()\n",
        "# train_df = train_df.sample(n=1800).reset_index()\n",
        "\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]"
      ],
      "metadata": {
        "id": "wwpgHsd19vH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traning Generator\n",
        "\n",
        "[ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"
      ],
      "metadata": {
        "id": "nS-2DgWS-uTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['category'] = train_df['category'].astype(str)"
      ],
      "metadata": {
        "id": "bNpKDpayW2Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate batches of tensor image data with real-time data augmentation.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "# Takes the dataframe and the path to a directory + generates batches. The generated batches contain augmented/normalized data.\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    \"../content/train/\",\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    class_mode='binary',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "eDAs7kp39zMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Generator"
      ],
      "metadata": {
        "id": "itmUc0mb-vQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validate_df['category'] = validate_df['category'].astype(str)"
      ],
      "metadata": {
        "id": "Wda2s0SBX_fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate batches of tensor image data with real-time data augmentation.\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255,horizontal_flip = True)\n",
        "\n",
        "# Takes the dataframe and the path to a directory + generates batches. The generated batches contain augmented/normalized data.\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df,\n",
        "    \"../content/train/\",\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    class_mode='binary',\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "Cle7O2hF92vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample generated images"
      ],
      "metadata": {
        "id": "jo3aBmaE-yGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
        "example_generator = train_datagen.flow_from_dataframe(\n",
        "    example_df,\n",
        "    \"/content/train\",\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    for X_batch, Y_batch in example_generator:\n",
        "        image = X_batch[0]\n",
        "        plt.imshow(image)\n",
        "        break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BT7IILr_9453"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit Model"
      ],
      "metadata": {
        "id": "kcN4hLLL-2PI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us fit the data to our model and measure the accuracy!"
      ],
      "metadata": {
        "id": "VUIaNQNl6CNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tune the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size)"
      ],
      "metadata": {
        "id": "Pr6mJJpx97U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(validation_generator, total_validate//batch_size, workers=12)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))"
      ],
      "metadata": {
        "id": "ZKHLd5f-99nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpreting Results and Error Analysis"
      ],
      "metadata": {
        "id": "_80yaRU35kza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n",
        "\n",
        "sns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"loss\"], ax = axes[0], label = \"Training Loss\")\n",
        "sns.lineplot(x = range(len(history.history[\"loss\"])), y = history.history[\"val_loss\"], ax = axes[0], label = \"Validation Loss\")\n",
        "\n",
        "sns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"accuracy\"], ax = axes[1], label = \"Training Accuracy\")\n",
        "sns.lineplot(x = range(len(history.history[\"accuracy\"])), y = history.history[\"val_accuracy\"], ax = axes[1], label = \"Validation Accuracy\")\n",
        "axes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n",
        "\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aUpe0073Rr7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Test Data\n"
      ],
      "metadata": {
        "id": "g44DV2R1Bw0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_filenames = os.listdir(\"../content/test1\")\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_filenames\n",
        "})\n",
        "nb_samples = test_df.shape[0]"
      ],
      "metadata": {
        "id": "--AwYWNM-SC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Testing Generator"
      ],
      "metadata": {
        "id": "PY8qhVJCB1AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate batches of tensor image data with real-time data augmentation.\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Takes the dataframe and the path to a directory + generates batches. The generated batches contain augmented/normalized data.\n",
        "test_generator = test_gen.flow_from_dataframe(\n",
        "    test_df.astype(str),\n",
        "    \"../content/test1/\",\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_size, image_size),\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "9gC0Bh19-UDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict"
      ],
      "metadata": {
        "id": "HJLotjIGB3sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the train model on test data\n",
        "predict = model.predict(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
        "threshold = 0.5\n",
        "test_df['category'] = np.where(predict > threshold, 1,0)"
      ],
      "metadata": {
        "id": "aVYJC6x3-WKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See predicted result"
      ],
      "metadata": {
        "id": "likHYcf5B6QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test = test_df.sample(n=9).reset_index()\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 12))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    img = load_img(\"../content/test1/\"+filename, target_size=(256, 256))\n",
        "    plt.subplot(3, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Asc5EmHg-Wxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ5DncB5kh-p"
      },
      "source": [
        "## Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgSwVENIPcM6"
      },
      "source": [
        "# @title What is the default input size for VGG16? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"\" #@param [\"\",\"32x32\", \"64x64\", \"128x128\", \"224x224\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzAZHt1zw-Y-",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}